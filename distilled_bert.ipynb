{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEPnsyy6s2av",
        "outputId": "df21b9d5-ff5d-4d33-962a-a8bb78c6216b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "没有可用的GPU，使用CPU。\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('有%d个GPU可用。' % torch.cuda.device_count())\n",
        "    print('我们将使用GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('没有可用的GPU，使用CPU。')\n",
        "    device = torch.device(\"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhoph7EFvLFn",
        "outputId": "a3dd3f30-7697-4718-93c6-15a28cc6106f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "   id                                               text  label\n",
            "0   0  This movie is a journey through the mind of a ...      1\n",
            "1   1  'Water' (2005), the final part of Toronto-base...      1\n",
            "2   2  This, which was shown dubbed in Italian at a R...      1\n",
            "3   3  Well, on the day that Rob Schneider plunges hi...      1\n",
            "4   4  I was watching an NFL game and started surfing...      1\n",
            "训练数据的数量: 30,000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive = drive.mount('/content/drive/')\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/Colab_Notebooks/hackthon/'  # Adjust the path as needed\n",
        "\n",
        "# List the contents of the folder\n",
        "folder_contents = os.listdir(folder_path)\n",
        "\n",
        "\n",
        "\n",
        "# 加载数据集\n",
        "df = pd.read_csv(folder_path+\"train.csv\")\n",
        "\n",
        "# 查看前几行数据\n",
        "print(df.head())\n",
        "print('训练数据的数量: {:,}\\n'.format(df.shape[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vpFAtOgveke"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'<[^>]+>', '', text)  # 去除 HTML 标签\n",
        "    text = re.sub(r'http\\S+|www\\S+', '', text)  # 去除 URL\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # 保留字母和空格\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # 去除多余空格\n",
        "    return text.lower()  # 转换为小写\n",
        "\n",
        "\n",
        "df['text'] = df['text'].apply(clean_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2VwAFPcxZKZ"
      },
      "outputs": [],
      "source": [
        "# 提取句子和标签\n",
        "sentences = df['text'].values\n",
        "labels = df['label'].values\n",
        "\n",
        "# 将标签转换为整数类型\n",
        "labels = labels.astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNZogcqMxsu4",
        "outputId": "f8fc750e-a25c-4b3a-8fa4-5e4be0357387"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "正在加载 BERT 分词器...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# from transformers import BertTokenizer\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "\n",
        "# 加载 BERT 分词器\n",
        "print('正在加载 BERT 分词器...')\n",
        "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Jc2TZY-x4kO"
      },
      "outputs": [],
      "source": [
        "# 设置最大序列长度\n",
        "MAX_LEN = 160  # 可以根据数据的平均长度进行调整\n",
        "# 对句子进行编码\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # 输入文本\n",
        "                        add_special_tokens = True, # 添加 '[CLS]' 和 '[SEP]'\n",
        "                        max_length = MAX_LEN,      # 填充和截断长度\n",
        "                        padding='max_length',\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # 返回 attention masks\n",
        "                        return_tensors = 'pt',     # 返回 PyTorch tensors 格式\n",
        "                   )\n",
        "\n",
        "    # 将编码后的文本加入列表\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# 将列表转换为 tensor\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMJ6W-OuyNUB"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 将数据集划分为训练集和验证集\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(\n",
        "    input_ids, labels, random_state=42, test_size=0.1\n",
        ")\n",
        "train_masks, validation_masks, _, _ = train_test_split(\n",
        "    attention_masks, labels, random_state=42, test_size=0.1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6STZDIny6il"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# 定义批量大小\n",
        "batch_size = 32  # 根据显存大小进行调整\n",
        "\n",
        "# 创建训练集的 DataLoader\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# 创建验证集的 DataLoader\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjeXod5v0dPl",
        "outputId": "2f088d78-c0af-429b-d2b4-9944a5c1a994"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DistilBertForSequenceClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): DistilBertSdpaAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = DistilBertForSequenceClassification.from_pretrained(\n",
        "    'distilbert-base-uncased',\n",
        "    num_labels=2,\n",
        "    output_attentions=False,\n",
        "    output_hidden_states=False,\n",
        ")\n",
        "\n",
        "\n",
        "# 将模型加载到 GPU 中\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wM6DzkMR0mBr",
        "outputId": "12782397-c982-49a3-c519-5deeff493ff5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import get_linear_schedule_with_warmup,AdamW\n",
        "\n",
        "# 设置优化器\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr = 2e-5,          # 学习率\n",
        "    eps = 1e-8          # AdamW 优化器的 epsilon 值\n",
        ")\n",
        "\n",
        "# 训练轮数\n",
        "epochs = 10\n",
        "\n",
        "# 总的训练步骤\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# 设置学习率调度器\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps = 0,\n",
        "    num_training_steps = total_steps\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPugQC570-9h"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Czm6q_Yw1CEQ"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    将时间转换为 hh:mm:ss 形式\n",
        "    '''\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbpwe_mH1EtA",
        "outputId": "7cfb6b63-c300-4d24-85b7-a4d65ec8a247"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 10 ========\n",
            "Training...\n",
            "in the batch0\n",
            "in the batch1\n",
            "in the batch2\n",
            "in the batch3\n",
            "in the batch4\n",
            "in the batch5\n",
            "in the batch6\n",
            "in the batch7\n",
            "in the batch8\n",
            "in the batch9\n",
            "in the batch10\n",
            "in the batch11\n",
            "in the batch12\n",
            "in the batch13\n",
            "in the batch14\n",
            "in the batch15\n",
            "in the batch16\n",
            "in the batch17\n",
            "in the batch18\n",
            "in the batch19\n",
            "in the batch20\n",
            "in the batch21\n",
            "in the batch22\n",
            "in the batch23\n",
            "in the batch24\n",
            "in the batch25\n",
            "in the batch26\n",
            "in the batch27\n",
            "in the batch28\n",
            "in the batch29\n",
            "in the batch30\n",
            "in the batch31\n",
            "in the batch32\n",
            "in the batch33\n",
            "in the batch34\n",
            "in the batch35\n",
            "in the batch36\n",
            "in the batch37\n",
            "in the batch38\n",
            "in the batch39\n",
            "in the batch40\n",
            "  Batch    40  of    844.    Elapsed: 0:18:03.\n",
            "in the batch41\n",
            "in the batch42\n",
            "in the batch43\n",
            "in the batch44\n",
            "in the batch45\n",
            "in the batch46\n",
            "in the batch47\n",
            "in the batch48\n",
            "in the batch49\n",
            "in the batch50\n",
            "in the batch51\n",
            "in the batch52\n",
            "in the batch53\n",
            "in the batch54\n",
            "in the batch55\n",
            "in the batch56\n",
            "in the batch57\n",
            "in the batch58\n",
            "in the batch59\n",
            "in the batch60\n",
            "in the batch61\n",
            "in the batch62\n",
            "in the batch63\n",
            "in the batch64\n",
            "in the batch65\n",
            "in the batch66\n",
            "in the batch67\n",
            "in the batch68\n",
            "in the batch69\n",
            "in the batch70\n",
            "in the batch71\n",
            "in the batch72\n",
            "in the batch73\n",
            "in the batch74\n",
            "in the batch75\n",
            "in the batch76\n",
            "in the batch77\n",
            "in the batch78\n",
            "in the batch79\n",
            "in the batch80\n",
            "  Batch    80  of    844.    Elapsed: 0:35:53.\n",
            "in the batch81\n",
            "in the batch82\n",
            "in the batch83\n",
            "in the batch84\n",
            "in the batch85\n",
            "in the batch86\n",
            "in the batch87\n",
            "in the batch88\n",
            "in the batch89\n",
            "in the batch90\n",
            "in the batch91\n",
            "in the batch92\n",
            "in the batch93\n",
            "in the batch94\n",
            "in the batch95\n",
            "in the batch96\n",
            "in the batch97\n",
            "in the batch98\n",
            "in the batch99\n",
            "in the batch100\n",
            "in the batch101\n",
            "in the batch102\n",
            "in the batch103\n",
            "in the batch104\n",
            "in the batch105\n",
            "in the batch106\n",
            "in the batch107\n",
            "in the batch108\n",
            "in the batch109\n",
            "in the batch110\n",
            "in the batch111\n",
            "in the batch112\n",
            "in the batch113\n",
            "in the batch114\n",
            "in the batch115\n",
            "in the batch116\n",
            "in the batch117\n",
            "in the batch118\n",
            "in the batch119\n",
            "in the batch120\n",
            "  Batch   120  of    844.    Elapsed: 0:53:38.\n",
            "in the batch121\n",
            "in the batch122\n",
            "in the batch123\n",
            "in the batch124\n",
            "in the batch125\n",
            "in the batch126\n",
            "in the batch127\n",
            "in the batch128\n",
            "in the batch129\n",
            "in the batch130\n",
            "in the batch131\n",
            "in the batch132\n",
            "in the batch133\n",
            "in the batch134\n",
            "in the batch135\n",
            "in the batch136\n",
            "in the batch137\n",
            "in the batch138\n",
            "in the batch139\n",
            "in the batch140\n",
            "in the batch141\n",
            "in the batch142\n",
            "in the batch143\n",
            "in the batch144\n",
            "in the batch145\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "# 设置随机种子\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# 存储损失值\n",
        "loss_values = []\n",
        "\n",
        "\n",
        "best_eval_accuracy = 0\n",
        "patience = 2  # 容忍的连续性能不提升的 epoch 数\n",
        "patience_counter = 0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    print('')\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "    total_loss = 0\n",
        "\n",
        "    # 将模型设置为训练模式\n",
        "    model.train()\n",
        "\n",
        "    # 训练数据循环\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # 每隔40个batch输出进度\n",
        "        print('in the batch{}'.format(step))\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # 将数据加载到 GPU 中\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # 清零梯度\n",
        "        model.zero_grad()\n",
        "\n",
        "        # 前向传播\n",
        "        outputs = model(\n",
        "            b_input_ids,\n",
        "            attention_mask=b_input_mask,\n",
        "            labels=b_labels\n",
        "        )\n",
        "\n",
        "        # 获取损失值\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # 反向传播\n",
        "        loss.backward()\n",
        "\n",
        "        # 梯度裁剪\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # 更新参数和学习率\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    # 计算平均损失\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    loss_values.append(avg_train_loss)\n",
        "    print('')\n",
        "    print('  平均训练损失: {0:.2f}'.format(avg_train_loss))\n",
        "    print('  训练 epoch 耗时: {:}'.format(format_time(time.time() - t0)))\n",
        "\n",
        "    # ========================================\n",
        "    #               验证\n",
        "    # ========================================\n",
        "    print('')\n",
        "    print('Running Validation...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # 设置模型为评估模式\n",
        "    model.eval()\n",
        "\n",
        "    eval_accuracy = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # 验证数据循环\n",
        "    for batch in validation_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(\n",
        "                b_input_ids,\n",
        "                attention_mask=b_input_mask\n",
        "            )\n",
        "\n",
        "        logits = outputs.logits\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        nb_eval_steps += 1\n",
        "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
        "\n",
        "    if eval_accuracy > best_eval_accuracy:\n",
        "      best_eval_accuracy = eval_accuracy\n",
        "      patience_counter = 0\n",
        "      # 保存模型\n",
        "      # model.save_pretrained(output_dir)\n",
        "      # tokenizer.save_pretrained(output_dir)\n",
        "    else:\n",
        "      patience_counter += 1\n",
        "      if patience_counter >= patience:\n",
        "          print('Early stopping due to no improvement in validation accuracy.')\n",
        "          break\n",
        "\n",
        "    print('  准确率: {0:.2f}'.format(eval_accuracy))\n",
        "    print('  验证耗时: {:}'.format(format_time(time.time() - t0)))\n",
        "\n",
        "print('')\n",
        "print('训练完成！')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "8glsWn021Hm5",
        "outputId": "df5f219f-3801-4821-9d5f-44255fb2865e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 绘制训练损失曲线\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Training loss\")\n",
        "plt.plot(loss_values)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gs4fR12sBtqn",
        "outputId": "01f83e07-0c0c-4aeb-8c4e-193193516c0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model to /content/drive/MyDrive/Colab_Notebooks/hackthon//model_save/\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/Colab_Notebooks/hackthon//model_save/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/Colab_Notebooks/hackthon//model_save/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/Colab_Notebooks/hackthon//model_save/vocab.txt',\n",
              " '/content/drive/MyDrive/Colab_Notebooks/hackthon//model_save/added_tokens.json')"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_dir = folder_path +'/model_2_save/'\n",
        "\n",
        "# 创建输出目录\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print('Saving model to %s' % output_dir)\n",
        "\n",
        "# 保存模型和分词器\n",
        "model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.quantization\n",
        "\n",
        "# 将模型移动到 CPU\n",
        "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
        "\n",
        "# 从 output_dir 加载未量化的模型和分词器\n",
        "model = DistilBertForSequenceClassification.from_pretrained(output_dir)\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(output_dir)\n",
        "\n",
        "# 将模型移动到 CPU，因为量化通常在 CPU 上进行\n",
        "model_cpu = model.cpu()\n",
        "\n",
        "# 对模型进行动态量化\n",
        "quantized_model = torch.quantization.quantize_dynamic(\n",
        "    model_cpu,\n",
        "    {torch.nn.Linear},\n",
        "    dtype=torch.qint8\n",
        ")\n",
        "\n",
        "# 保存量化后的模型\n",
        "quantized_model_save_path = os.path.join(output_dir, 'quantized_model.pth')\n",
        "torch.save(quantized_model.state_dict(), quantized_model_save_path)\n",
        "print('量化后的模型已保存到 %s' % quantized_model_save_path)\n",
        "# tokenizer.save_pretrained(output_dir)\n",
        "# print('分词器已保存到 %s' % output_dir)\n"
      ],
      "metadata": {
        "id": "PqPSfiUdoheb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NN67yW1CGXd",
        "outputId": "bb4947c3-20e1-4ed8-c2f0-8310385b24da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained(output_dir)\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(output_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pwas2T8GLNyf",
        "outputId": "69e8db75-0baa-48a4-d538-09c1218fe250"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Positive\n"
          ]
        }
      ],
      "source": [
        "def predict(sentence):\n",
        "    # 对输入句子进行编码\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sentence,                   # 输入句子\n",
        "                        add_special_tokens = True,  # 添加 '[CLS]' 和 '[SEP]'\n",
        "                        max_length = MAX_LEN,       # 填充和截断长度\n",
        "                        padding='max_length',\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt',      # 返回 PyTorch tensors 格式\n",
        "                   )\n",
        "\n",
        "    # 将数据移动到 GPU\n",
        "    input_id = encoded_dict['input_ids'].to(device)\n",
        "    attention_mask = encoded_dict['attention_mask'].to(device)\n",
        "\n",
        "    # 设置模型为评估模式\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_id, attention_mask=attention_mask)\n",
        "\n",
        "    logits = outputs.logits\n",
        "\n",
        "    # 获取预测结果\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    prediction = np.argmax(logits, axis=1).flatten()\n",
        "\n",
        "    if prediction == 0:\n",
        "        print(\"Negative\")\n",
        "    else:\n",
        "        print(\"Positive\")\n",
        "\n",
        "# 测试示例\n",
        "predict(\"This movie is fantastic! I really enjoyed it.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1C9h5FWUPs8"
      },
      "outputs": [],
      "source": [
        "import torch.quantization\n",
        "\n",
        "# 将模型移动到 CPU\n",
        "model_cpu = model.cpu()\n",
        "\n",
        "# 对模型进行动态量化\n",
        "quantized_model = torch.quantization.quantize_dynamic(\n",
        "    model_cpu,\n",
        "    {torch.nn.Linear},\n",
        "    dtype=torch.qint8\n",
        ")\n",
        "\n",
        "# 保存量化后的模型\n",
        "quantized_model_save_path = os.path.join(output_dir, 'quantized_model.pth')\n",
        "torch.save(quantized_model, quantized_model_save_path)\n",
        "print('量化后的模型已保存到 %s' % quantized_model_save_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quantized_model_save_path = os.path.join(output_dir, 'quantized_model.pth')"
      ],
      "metadata": {
        "id": "mQZKxR_R6wK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_model_dir = output_dir\n",
        "student_model_dir = output_dir+'student'\n",
        "if not os.path.exists(student_model_dir):\n",
        "    os.makedirs(student_model_dir)\n",
        "\n",
        "teacher_model = DistilBertForSequenceClassification.from_pretrained(teacher_model_dir)\n",
        "teacher_model.to('cpu')  # 教师模型在 CPU 上\n",
        "teacher_model.eval()\n",
        "for param in teacher_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# 定义学生模型配置（更小的模型）\n",
        "student_config = DistilBertConfig(\n",
        "    n_layers=3,                 # 减少层数\n",
        "    dim=256,                    # 减少隐藏层维度\n",
        "    n_heads=4,                  # 减少注意力头数\n",
        "    dim_feedforward=1024,       # 维持前馈层大小\n",
        "    dropout=0.1,                # Dropout 率\n",
        "    max_position_embeddings=160,# 与输入长度一致\n",
        "    n_labels=2                  # 根据任务调整\n",
        ")\n",
        "\n",
        "# 初始化学生模型\n",
        "student_model = DistilBertForSequenceClassification(student_config)\n",
        "student_model.to(device)\n",
        "\n",
        "# 加载分词器\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(teacher_model_dir)\n",
        "\n",
        "# 编码训练数据\n",
        "train_encodings = tokenizer.batch_encode_plus(\n",
        "    train_df['text'].tolist(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=160,\n",
        "    padding='max_length',\n",
        "    truncation=True,\n",
        "    return_attention_mask=True,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "def distillation_loss(student_logits, teacher_logits, labels, T=2.0, alpha=0.5):\n",
        "    \"\"\"\n",
        "    计算蒸馏损失。\n",
        "\n",
        "    参数：\n",
        "    - student_logits: 学生模型的输出 logits\n",
        "    - teacher_logits: 教师模型的输出 logits\n",
        "    - labels: 真实标签\n",
        "    - T: 温度参数\n",
        "    - alpha: 蒸馏损失的权重\n",
        "    \"\"\"\n",
        "    # 计算蒸馏损失（KL散度）\n",
        "    loss_kd = F.kl_div(\n",
        "        F.log_softmax(student_logits / T, dim=1),\n",
        "        F.softmax(teacher_logits / T, dim=1),\n",
        "        reduction='batchmean'\n",
        "    ) * (T ** 2)\n",
        "\n",
        "    # 计算分类损失（交叉熵）\n",
        "    loss_ce = F.cross_entropy(student_logits, labels)\n",
        "\n",
        "    # 总损失\n",
        "    loss = alpha * loss_ce + (1. - alpha) * loss_kd\n",
        "    return loss\n",
        "\n",
        "\n",
        "for epoch_i in range(epochs):\n",
        "    print('')\n",
        "    print(f'======== Epoch {epoch_i + 1} / {epochs} ========')\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "    total_loss = 0\n",
        "\n",
        "    # 将学生模型设置为训练模式\n",
        "    student_model.train()\n",
        "\n",
        "    # 训练数据循环\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = time.time() - t0\n",
        "            print(f'  Batch {step} of {len(train_dataloader)}.    Elapsed: {elapsed:.2f} seconds.')\n",
        "\n",
        "        # 获取输入数据并移动到设备\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # 清零梯度\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 教师模型输出（在 CPU 上，无需计算梯度）\n",
        "        with torch.no_grad():\n",
        "            outputs_teacher = teacher_model(\n",
        "                batch[0].to('cpu'),             # 输入数据移动到 CPU\n",
        "                attention_mask=batch[1].to('cpu')  # 注意力掩码移动到 CPU\n",
        "            )\n",
        "            logits_teacher = outputs_teacher.logits\n",
        "\n",
        "        # 学生模型输出（在 GPU 上）\n",
        "        outputs_student = student_model(\n",
        "            b_input_ids,\n",
        "            attention_mask=b_input_mask\n",
        "        )\n",
        "        logits_student = outputs_student.logits\n",
        "\n",
        "        # 将教师模型的 logits 移动到 GPU\n",
        "        logits_teacher = logits_teacher.to(device)\n",
        "\n",
        "        # 计算蒸馏损失\n",
        "        loss = distillation_loss(\n",
        "            logits_student,\n",
        "            logits_teacher,\n",
        "            b_labels,\n",
        "            T=2.0,\n",
        "            alpha=0.5\n",
        "        )\n",
        "\n",
        "        # 反向传播\n",
        "        loss.backward()\n",
        "\n",
        "        # 梯度裁剪\n",
        "        torch.nn.utils.clip_grad_norm_(student_model.parameters(), 1.0)\n",
        "\n",
        "        # 更新参数和学习率\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # 累加损失值\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # 计算平均训练损失\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print('')\n",
        "    print(f'  平均训练损失: {avg_train_loss:.2f}')\n",
        "    print(f'  训练 epoch 耗时: {time.time() - t0:.2f} seconds')\n",
        "\n",
        "    # ========================================\n",
        "    #               验证\n",
        "    # ========================================\n",
        "    print('')\n",
        "    print('Running Validation...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # 设置学生模型为评估模式\n",
        "    student_model.eval()\n",
        "\n",
        "    eval_accuracy = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # 验证数据循环\n",
        "    with torch.no_grad():\n",
        "        for batch in validation_dataloader:\n",
        "            batch_input_ids = batch[0].to(device)\n",
        "            batch_attention_mask = batch[1].to(device)\n",
        "            batch_labels = batch[2].to(device)\n",
        "\n",
        "            # 学生模型输出\n",
        "            outputs = student_model(\n",
        "                batch_input_ids,\n",
        "                attention_mask=batch_attention_mask\n",
        "            )\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # 将 logits 转换为 FP32 以提高数值稳定性\n",
        "            logits = logits.float()\n",
        "\n",
        "            # 获取预测结果\n",
        "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "            labels = batch_labels.cpu().numpy()\n",
        "\n",
        "            tmp_eval_accuracy = flat_accuracy(preds, labels)\n",
        "\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "            nb_eval_steps += 1\n",
        "\n",
        "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
        "\n",
        "    if eval_accuracy > best_eval_accuracy:\n",
        "        best_eval_accuracy = eval_accuracy\n",
        "        patience_counter = 0\n",
        "        # 保存最佳学生模型\n",
        "\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print('Early stopping due to no improvement in validation accuracy.')\n",
        "            break\n",
        "\n",
        "    print(f'  准确率: {eval_accuracy:.2f}')\n",
        "    print(f'  验证耗时: {time.time() - t0:.2f} seconds')\n",
        "\n",
        "print('')\n",
        "print('训练完成！')\n",
        "student_model.save_pretrained(student_model_dir)\n",
        "tokenizer.save_pretrained(student_model_dir)\n",
        "print(f'  保存最佳模型，当前最佳准确率: {best_eval_accuracy:.2f}')"
      ],
      "metadata": {
        "id": "onYOTlBt6wgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xg-rY5xKm9sF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}